{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Third-Party Imports\n",
    "from PIL import Image\n",
    "import skimage.io as sk_io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Local Imports\n",
    "from utils.COCO_utils import get_most_common_cat, initialize_coco, process_coco_data, create_dataframe, get_unique_entries, save_dataframe_coco, load_dataframe_coco\n",
    "from utils.NSD_utils import download_and_process_nsd_data, assign_main_category, save_dataframes_nsd, load_dataframes_nsd\n",
    "\n",
    "# Configure Matplotlib settings\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "\n",
    "# Ensure correct path for relative imports\n",
    "sys.path.insert(0, '/Users/davide/Documents/Work/github/model_training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize COCO-NSD category mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script initializes and maps COCO dataset category numbers to category names and vice versa.\n",
    "It also adjusts COCO categories to align with specific needs, like the NSD (Neural Stimulus Decoding) format.\n",
    "\"\"\"\n",
    "\n",
    "# COCO Category Mapping (Original) - maps category numbers to their respective names in the COCO dataset\n",
    "coco_num_to_cat_original = {\n",
    "    1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane',\n",
    "    6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light',\n",
    "    11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench',\n",
    "    16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep',\n",
    "    21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe',\n",
    "    27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie', 33: 'suitcase',\n",
    "    34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite',\n",
    "    39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard', 42: 'surfboard', 43: 'tennis racket',\n",
    "    44: 'bottle', 46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife',\n",
    "    50: 'spoon', 51: 'bowl', 52: 'banana', 53: 'apple', 54: 'sandwich',\n",
    "    55: 'orange', 56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza',\n",
    "    60: 'donut', 61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant',\n",
    "    65: 'bed', 67: 'dining table', 70: 'toilet', 72: 'tv', 73: 'laptop',\n",
    "    74: 'mouse', 75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave',\n",
    "    79: 'oven', 80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book',\n",
    "    85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier', 90: 'toothbrush'\n",
    "}\n",
    "\n",
    "# Adjusted COCO Category Mapping for NSD (Maps category numbers from 1 to 80)\n",
    "# This dictionary remaps COCO categories to fit a specific range for use with the NSD dataset.\n",
    "sub_number_map = {key: i + 1 for i, key in enumerate(list(coco_num_to_cat_original.keys())[:80])}\n",
    "\n",
    "# Cleaned COCO Category Mapping (Reduced to 80 categories) - to map category numbers to category names\n",
    "coco_num_to_cat = {\n",
    "    1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus', 7: 'train', \n",
    "    8: 'truck', 9: 'boat', 10: 'traffic light', 11: 'fire hydrant', 12: 'stop sign', \n",
    "    13: 'parking meter', 14: 'bench', 15: 'bird', 16: 'cat', 17: 'dog', 18: 'horse', \n",
    "    19: 'sheep', 20: 'cow', 21: 'elephant', 22: 'bear', 23: 'zebra', 24: 'giraffe', \n",
    "    25: 'backpack', 26: 'umbrella', 27: 'handbag', 28: 'tie', 29: 'suitcase', 30: 'frisbee', \n",
    "    31: 'skis', 32: 'snowboard', 33: 'sports ball', 34: 'kite', 35: 'baseball bat', \n",
    "    36: 'baseball glove', 37: 'skateboard', 38: 'surfboard', 39: 'tennis racket', \n",
    "    40: 'bottle', 41: 'wine glass', 42: 'cup', 43: 'fork', 44: 'knife', 45: 'spoon', \n",
    "    46: 'bowl', 47: 'banana', 48: 'apple', 49: 'sandwich', 50: 'orange', 51: 'broccoli', \n",
    "    52: 'carrot', 53: 'hot dog', 54: 'pizza', 55: 'donut', 56: 'cake', 57: 'chair', \n",
    "    58: 'couch', 59: 'potted plant', 60: 'bed', 61: 'dining table', 62: 'toilet', 63: 'tv', \n",
    "    64: 'laptop', 65: 'mouse', 66: 'remote', 67: 'keyboard', 68: 'cell phone', \n",
    "    69: 'microwave', 70: 'oven', 71: 'toaster', 72: 'sink', 73: 'refrigerator', \n",
    "    74: 'book', 75: 'clock', 76: 'vase', 77: 'scissors', 78: 'teddy bear', 79: 'hair drier', \n",
    "    80: 'toothbrush'\n",
    "}\n",
    "\n",
    "# Reverse COCO Category Mapping (Maps category names to category numbers)\n",
    "coco_cat_to_num = {v: k for k, v in coco_num_to_cat.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get COCO info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main script settings\n",
    "data_dir = '/Users/davide/Documents/Work/MS_COCO/Images'\n",
    "store_path = '/Users/davide/Documents/Work/MS_COCO/data/coco_full.csv'\n",
    "run_processing = 0\n",
    "save_to_file = 0\n",
    "load_from_file = 1\n",
    "\n",
    "# Execution logic\n",
    "if run_processing:\n",
    "    sets = ['val2017', 'train2017']\n",
    "    coco_cat_n, coco_cat_s, coco_id, coco_captions = [], [], [], []\n",
    "    \n",
    "    for dataset in sets:\n",
    "        coco, coco_caps = initialize_coco(data_dir, dataset)\n",
    "        cat_n, cat_s, ids, captions = process_coco_data(coco, coco_caps, coco_num_to_cat_original)\n",
    "        coco_cat_n.extend(cat_n)\n",
    "        coco_cat_s.extend(cat_s)\n",
    "        coco_id.extend(ids)\n",
    "        coco_captions.extend(captions)\n",
    "    \n",
    "    coco_pd_full = create_dataframe(coco_cat_n, coco_cat_s, coco_id, coco_captions, sub_number_map)\n",
    "    coco_pd = get_unique_entries(coco_pd_full)\n",
    "\n",
    "if save_to_file:\n",
    "    save_dataframe_coco(coco_pd, store_path)\n",
    "\n",
    "if load_from_file:\n",
    "    coco_pd = load_dataframe_coco(store_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get NSD info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/davide/Documents/Work/MS_COCO/data/'\n",
    "run_processing = 0\n",
    "save_to_file = 0\n",
    "load_from_file = 1\n",
    "\n",
    "# URL for downloading the NSD dataset\n",
    "nsd_data_url = \"https://natural-scenes-dataset.s3.amazonaws.com/nsddata/experiments/nsd/nsd_stim_info_merged.csv\"\n",
    "\n",
    "if run_processing:\n",
    "    # Step 1: Download and process NSD data\n",
    "    nsd_allCat = download_and_process_nsd_data(nsd_data_url, coco_pd)\n",
    "    \n",
    "    # Step 2: Assign the main category and get single category data\n",
    "    nsd_allCat, nsd_singleCat = assign_main_category(nsd_allCat)\n",
    "\n",
    "if save_to_file:\n",
    "    # Save the processed data to disk\n",
    "    save_dataframes_nsd(nsd_allCat, nsd_singleCat, data_path)\n",
    "\n",
    "if load_from_file:\n",
    "    # Load previously saved data from disk\n",
    "    nsd_allCat, nsd_singleCat = load_dataframes_nsd(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get multi-labelled images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script processes and filters MS COCO dataset annotations to create a subset of data based on the number of exemplars per category.\n",
    "\n",
    "### Configuration\n",
    "- `data_path` (str): Directory where data files are stored.\n",
    "- `run` (int): Flag to indicate whether to run the processing and filtering steps (1 to run, 0 to skip).\n",
    "- `store` (int): Flag to indicate whether to save the processed data to a file (1 to save, 0 to skip).\n",
    "- `load` (int): Flag to indicate whether to load previously processed data from a file (1 to load, 0 to skip).\n",
    "\n",
    "### Parameters\n",
    "- `n` (int): Minimum number of images required per category to be included in the final dataset.\n",
    "- `include_persons` (bool): Flag to include the 'person' category (category 1) in the processed data.\n",
    "\n",
    "### Process Overview\n",
    "1. **Loading Data**: If the `load` flag is set to 1, it loads the previously saved data from 'nsd_allCat.csv' and 'nsd_singleCat.csv' using `pickle`.\n",
    "\n",
    "2. **Filtering Categories**:\n",
    "    - It filters categories in `nsd_singleCat` that have at least `n` exemplars and excludes category 1 (person) if `include_persons` is False.\n",
    "    - It creates a set of categories to keep based on this filtering.\n",
    "\n",
    "3. **Subsetting Data**:\n",
    "    - Removes rows from `nsd_allCat` where 'main_cat' is NaN.\n",
    "    - Converts 'main_cat' to numerical values.\n",
    "    - Subsets `nsd_allCat` to include only the rows where 'main_cat' matches the filtered categories.\n",
    "\n",
    "4. **Processing for Non-Overlapping Categories**:\n",
    "    - For each row in the subset DataFrame, it identifies categories other than the main category.\n",
    "    - It determines if these other categories are not in the set of categories to keep.\n",
    "    - It creates a list of indices where no other categories overlap with the categories to keep.\n",
    "\"\"\"\n",
    "\n",
    "# Configuration\n",
    "data_path = '/Users/davide/Documents/Work/MS_COCO/data/'\n",
    "run = 0\n",
    "store = 1\n",
    "load = 0\n",
    "\n",
    "# Parameters\n",
    "n = 75  # Minimum number of images per category to keep\n",
    "include_persons = False  # Flag to include the 'person' category (category 1)\n",
    "\n",
    "# Load data (assuming data has been loaded previously into nsd_singleCat and nsd_allCat)\n",
    "if load:\n",
    "    with open(os.path.join(data_path, 'nsd_allCat.csv'), 'rb') as f:\n",
    "        nsd_allCat = pickle.load(f)\n",
    "    with open(os.path.join(data_path, 'nsd_singleCat.csv'), 'rb') as f:\n",
    "        nsd_singleCat = pickle.load(f)\n",
    "\n",
    "if run:\n",
    "    # Filter categories with at least `n` exemplars\n",
    "    cat_counts = nsd_singleCat['cat_n'].value_counts()\n",
    "    mask = cat_counts > n\n",
    "    cat_sub = cat_counts[mask]\n",
    "    cat_sub = [i[0] for i in cat_sub.index if i[0] != 1]  # Exclude category 1 (person)\n",
    "    cat_to_keep = set(np.array(cat_sub))\n",
    "    cat_to_keep_str = [coco_num_to_cat[val] for val in cat_to_keep]\n",
    "\n",
    "    # Filter out rows where 'main_cat' is NaN\n",
    "    nsd_allCat_naSub = nsd_allCat[~nsd_allCat['main_cat'].isna()]\n",
    "    nsd_allCat_naSub['main_cat_n'] = nsd_allCat_naSub['main_cat'].map(coco_cat_to_num)\n",
    "\n",
    "    # Subset DataFrame to keep only relevant categories\n",
    "    nsd_allCat_sub = nsd_allCat_naSub[nsd_allCat_naSub['main_cat'].isin(cat_to_keep_str)]\n",
    "\n",
    "    # Initialize lists\n",
    "    other_cats_n = []\n",
    "    non_overlapping_cat_idx = []\n",
    "\n",
    "    if not include_persons:\n",
    "        cat_to_keep.add(1)  # Include category 1 if needed\n",
    "\n",
    "    # Process DataFrame to find non-overlapping categories\n",
    "    for idx in range(len(nsd_allCat_sub)):\n",
    "        act_cats = nsd_allCat_sub.iloc[idx]['cat_n']\n",
    "        act_main_cat = nsd_allCat_sub.iloc[idx]['main_cat_n']\n",
    "        filtered_list = [elem for elem in act_cats if elem != act_main_cat]\n",
    "        other_cats_n.append(filtered_list)\n",
    "        result = all(elem not in cat_to_keep for elem in filtered_list)\n",
    "        if result:\n",
    "            non_overlapping_cat_idx.append(idx)\n",
    "\n",
    "    nsd_allCat_sub['other_cats_n'] = other_cats_n\n",
    "    nsd_noOverlap = nsd_allCat_sub.iloc[non_overlapping_cat_idx]\n",
    "\n",
    "if store:\n",
    "    if include_persons:\n",
    "        with open(os.path.join(data_path, 'nsd_noOverlap.csv'), 'wb') as f:\n",
    "            pickle.dump(nsd_noOverlap, f)\n",
    "    else:\n",
    "        with open(os.path.join(data_path, 'nsd_noOverlap_noPersons.csv'), 'wb') as f:\n",
    "            pickle.dump(nsd_noOverlap, f)        \n",
    "\n",
    "if load:\n",
    "    if include_persons:\n",
    "        with open(os.path.join(data_path, 'nsd_noOverlap.csv'), 'rb') as f:\n",
    "            nsd_noOverlap = pickle.load(f)\n",
    "    else:    \n",
    "        with open(os.path.join(data_path, 'nsd_noOverlap_noPersons.csv'), 'rb') as f:\n",
    "            nsd_noOverlap = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping and storing images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding path 0\n",
      "Adding path 5000\n",
      "Adding path 10000\n",
      "Adding path 15000\n",
      "Start cropping and saving images\n",
      "Processing image 0\n",
      "Processing image 100\n",
      "Processing image 200\n",
      "Processing image 300\n",
      "Processing image 400\n",
      "Processing image 500\n",
      "Processing image 600\n",
      "Processing image 700\n",
      "Processing image 800\n",
      "Processing image 900\n",
      "Processing image 1000\n",
      "Processing image 1100\n",
      "Processing image 1200\n",
      "Processing image 1300\n",
      "Processing image 1400\n",
      "Processing image 1500\n",
      "Processing image 1600\n",
      "Processing image 1700\n",
      "Processing image 1800\n",
      "Processing image 1900\n",
      "Processing image 2000\n",
      "Processing image 2100\n",
      "Processing image 2200\n",
      "Processing image 2300\n",
      "Processing image 2400\n",
      "Processing image 2500\n",
      "Processing image 2600\n",
      "Processing image 2700\n",
      "Processing image 2800\n",
      "Processing image 2900\n",
      "Processing image 3000\n",
      "Processing image 3100\n",
      "Processing image 3200\n",
      "Processing image 3300\n",
      "Processing image 3400\n",
      "Processing image 3500\n",
      "Processing image 3600\n",
      "Processing image 3700\n",
      "Processing image 3800\n",
      "Processing image 3900\n",
      "Processing image 4000\n",
      "Processing image 4100\n",
      "Processing image 4200\n",
      "Processing image 4300\n",
      "Processing image 4400\n",
      "Processing image 4500\n",
      "Processing image 4600\n",
      "Processing image 4700\n",
      "Processing image 4800\n",
      "Processing image 4900\n",
      "Processing image 5000\n",
      "Processing image 5100\n",
      "Processing image 5200\n",
      "Processing image 5300\n",
      "Processing image 5400\n",
      "Processing image 5500\n",
      "Processing image 5600\n",
      "Processing image 5700\n",
      "Processing image 5800\n",
      "Processing image 5900\n",
      "Processing image 6000\n",
      "Processing image 6100\n",
      "Processing image 6200\n",
      "Processing image 6300\n",
      "Processing image 6400\n",
      "Processing image 6500\n",
      "Processing image 6600\n",
      "Processing image 6700\n",
      "Processing image 6800\n",
      "Processing image 6900\n",
      "Processing image 7000\n",
      "Processing image 7100\n",
      "Processing image 7200\n",
      "Processing image 7300\n",
      "Processing image 7400\n",
      "Processing image 7500\n",
      "Processing image 7600\n",
      "Processing image 7700\n",
      "Processing image 7800\n",
      "Processing image 7900\n",
      "Processing image 8000\n",
      "Processing image 8100\n",
      "Processing image 8200\n",
      "Processing image 8300\n",
      "Processing image 8400\n",
      "Processing image 8500\n",
      "Processing image 8600\n",
      "Processing image 8700\n",
      "Processing image 8800\n",
      "Processing image 8900\n",
      "Processing image 9000\n",
      "Processing image 9100\n",
      "Processing image 9200\n",
      "Processing image 9300\n",
      "Processing image 9400\n",
      "Processing image 9500\n",
      "Processing image 9600\n",
      "Processing image 9700\n",
      "Processing image 9800\n",
      "Processing image 9900\n",
      "Processing image 10000\n",
      "Processing image 10100\n",
      "Processing image 10200\n",
      "Processing image 10300\n",
      "Processing image 10400\n",
      "Processing image 10500\n",
      "Processing image 10600\n",
      "Processing image 10700\n",
      "Processing image 10800\n",
      "Processing image 10900\n",
      "Processing image 11000\n",
      "Processing image 11100\n",
      "Processing image 11200\n",
      "Processing image 11300\n",
      "Processing image 11400\n",
      "Processing image 11500\n",
      "Processing image 11600\n",
      "Processing image 11700\n",
      "Processing image 11800\n",
      "Processing image 11900\n",
      "Processing image 12000\n",
      "Processing image 12100\n",
      "Processing image 12200\n",
      "Processing image 12300\n",
      "Processing image 12400\n",
      "Processing image 12500\n",
      "Processing image 12600\n",
      "Processing image 12700\n",
      "Processing image 12800\n",
      "Processing image 12900\n",
      "Processing image 13000\n",
      "Processing image 13100\n",
      "Processing image 13200\n",
      "Processing image 13300\n",
      "Processing image 13400\n",
      "Processing image 13500\n",
      "Processing image 13600\n",
      "Processing image 13700\n",
      "Processing image 13800\n",
      "Processing image 13900\n",
      "Processing image 14000\n",
      "Processing image 14100\n",
      "Processing image 14200\n",
      "Processing image 14300\n",
      "Processing image 14400\n",
      "Processing image 14500\n",
      "Processing image 14600\n",
      "Processing image 14700\n",
      "Processing image 14800\n",
      "Processing image 14900\n",
      "Processing image 15000\n",
      "Processing image 15100\n",
      "Processing image 15200\n",
      "Processing image 15300\n",
      "Processing image 15400\n",
      "Processing image 15500\n",
      "Processing image 15600\n",
      "Processing image 15700\n",
      "Processing image 15800\n",
      "Processing image 15900\n",
      "Processing image 16000\n",
      "Processing image 16100\n",
      "Processing image 16200\n",
      "Processing image 16300\n",
      "Processing image 16400\n",
      "Processing image 16500\n",
      "Processing image 16600\n",
      "Processing image 16700\n",
      "Processing image 16800\n",
      "Processing image 16900\n",
      "Processing image 17000\n",
      "Processing image 17100\n",
      "Processing image 17200\n",
      "Processing image 17300\n",
      "Processing image 17400\n",
      "Processing image 17500\n",
      "Processing image 17600\n",
      "Processing image 17700\n",
      "Finished processing images for dataset: nsd_singleCat\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "data_path = '/Users/davide/Documents/Work/MS_COCO/data/'\n",
    "which_dataset = 'nsd_singleCat'  # Options: 'nsd_singleCat', 'nsd_noOverlap', 'nsd_noOverlap_noPersons'\n",
    "\n",
    "# Load data based on the dataset selection\n",
    "datasets = {\n",
    "    'nsd_singleCat': 'nsd_singleCat.csv',\n",
    "    'nsd_noOverlap': 'nsd_noOverlap.csv',\n",
    "    'nsd_noOverlap_noPersons': 'nsd_noOverlap_noPersons.csv'\n",
    "}\n",
    "\n",
    "dataset_file = datasets.get(which_dataset)\n",
    "with open(os.path.join(data_path, dataset_file), 'rb') as f:\n",
    "    pd_to_use = pickle.load(f)\n",
    "\n",
    "# Define directories\n",
    "directories = {\n",
    "    'nsd_singleCat': '/Users/davide/Documents/Work/MS_COCO/nsd_images/single_cat/',\n",
    "    'nsd_noOverlap': '/Users/davide/Documents/Work/MS_COCO/nsd_images/multiple_cats/',\n",
    "    'nsd_noOverlap_noPersons': '/Users/davide/Documents/Work/MS_COCO/nsd_images/multiple_cats_no_persons/'\n",
    "}\n",
    "\n",
    "cropped_images_path = directories.get(which_dataset)\n",
    "\n",
    "# Flags\n",
    "make_cat_dir = 1\n",
    "run_crop = 1\n",
    "\n",
    "# Create directories if needed\n",
    "def create_dirs(directory, categories):\n",
    "    for category in categories:\n",
    "        cat_path = os.path.join(directory, category)\n",
    "        if not os.path.isdir(cat_path):\n",
    "            os.makedirs(cat_path)\n",
    "\n",
    "if make_cat_dir:\n",
    "    categories = [cat for cat in pd_to_use['main_cat'].unique() if not pd.isna(cat)]\n",
    "    create_dirs(cropped_images_path, categories)\n",
    "\n",
    "# Prepare paths and move images if write flag is set\n",
    "\n",
    "source_paths = []\n",
    "destination_paths = []\n",
    "nsd_pd = pd_to_use[pd.notna(pd_to_use['main_cat'])].reset_index(drop=True)\n",
    "coco_imgs_folder = '/Users/davide/Documents/Work/MS_COCO/Images/trainVal2017/'\n",
    "\n",
    "for img in range(len(nsd_pd)):\n",
    "    if img % 5000 == 0: print(f'Adding path {img}')\n",
    "    act_id = nsd_pd.loc[img, 'id']\n",
    "    act_nsd_id = nsd_pd.loc[img, 'nsdId']\n",
    "    act_cat = nsd_pd.loc[img, 'main_cat']\n",
    "    act_img_name = '0' * (12 - len(str(act_id))) + str(act_id) + '.jpg'\n",
    "    act_nsd_name = str(act_nsd_id) + '.jpg'\n",
    "    source_path = os.path.join(coco_imgs_folder, act_img_name)\n",
    "    destination_path = os.path.join(cropped_images_path, act_cat, act_nsd_name)\n",
    "    source_paths.append(source_path)\n",
    "    destination_paths.append(destination_path)\n",
    "\n",
    "nsd_pd['source_paths'] = source_paths\n",
    "nsd_pd['destination_paths'] = destination_paths\n",
    "\n",
    "print('\\n\\nStart cropping and saving images')\n",
    "\n",
    "# Crop and resize images if run_crop flag is set\n",
    "if run_crop:\n",
    "    resize_dim = (425, 425)\n",
    "\n",
    "    for i in range(len(nsd_pd)):\n",
    "        if i % 100 == 0: print(f'Processing image {i}')\n",
    "\n",
    "        source_path = nsd_pd.loc[i]['source_paths']\n",
    "        destination_path = nsd_pd.loc[i]['destination_paths']\n",
    "        act_crop_box = nsd_pd.loc[i]['cropBox']\n",
    "        \n",
    "        # Convert crop box into a tuple\n",
    "        crop_box_str = act_crop_box.strip().strip('()')\n",
    "        act_crop_box_t = tuple(map(float, crop_box_str.split(',')))\n",
    "\n",
    "        if not os.path.isfile(source_path):\n",
    "            print(f'Warning: File not found {source_path}') \n",
    "            continue\n",
    "\n",
    "        with Image.open(source_path) as img:\n",
    "            w, h = img.size\n",
    "            \n",
    "            # Unpack crop_info \n",
    "            top_pct, bottom_pct, left_pct, right_pct = act_crop_box_t\n",
    "\n",
    "            # Calculate pixel values for the crop box\n",
    "            left = int(left_pct * w)\n",
    "            top = int(top_pct * h)\n",
    "            right = int((1 - right_pct) * w)\n",
    "            bottom = int((1 - bottom_pct) * h)  \n",
    "\n",
    "            # Crop the image\n",
    "            cropped_img = img.crop((left, top, right, bottom))\n",
    "            resized_img = cropped_img.resize(resize_dim, Image.Resampling.LANCZOS)\n",
    "            \n",
    "            # Save the cropped and resized image\n",
    "            resized_img.save(destination_path)\n",
    "\n",
    "    print(f'Finished processing images for dataset: {which_dataset}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
